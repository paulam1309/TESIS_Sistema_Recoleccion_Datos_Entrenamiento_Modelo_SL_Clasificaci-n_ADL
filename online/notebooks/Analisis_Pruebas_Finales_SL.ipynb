{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNDnd32ZRHTfuMdl8B2//OZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**An√°lisis intensivo de pruebas finales'.**\n","\n","Modelos:\n","- SVM offline (columna pred_label)\n","- HT online (columna actividad)\n","- ARF online (columna actividad_b)\n","\n","Calcula:\n","1) Matrices de confusi√≥n (PNG).\n","2) Tiempo de reacci√≥n ante cambios de actividad (lag entre cambio en etiqueta y primera predicci√≥n correcta).\n","3) Curvas de aprendizaje (rolling accuracy) para HT/ARF:\n","4) Estabilidad (\"chattering\": switches/min de las predicciones)."],"metadata":{"id":"dWnTF3gUUZPf"}},{"cell_type":"markdown","source":["**IMPORTACI√ìN DE LIBRERIAS**"],"metadata":{"id":"Qp3ouASsUj08"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import argparse\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from pathlib import Path\n","import os"],"metadata":{"id":"qB7qEKhQUmzm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763507431067,"user_tz":300,"elapsed":36706,"user":{"displayName":"PAULA SOFIA MUNOZ ORDONEZ","userId":"07412303973976148016"}},"outputId":"8db8f7cc-4f3f-479c-df14-d87f96a9f9a0"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["*Configuraciones*"],"metadata":{"id":"S-w1xoGz4mk2"}},{"cell_type":"code","source":["# ======================= RUTAS =======================\n","INPUT_CSV = \"/content/drive/MyDrive/Colab Notebooks/TESIS/FASE ONLINE/ARCHIVOS ONLINE/windows.csv\"\n","OUT_DIR   = \"/content/drive/MyDrive/Colab Notebooks/TESIS/FASE ONLINE/RESULTADOS_SL\"\n","\n","print(\"CSV existe?\", os.path.exists(INPUT_CSV), INPUT_CSV)\n","\n","BAD_LABELS = {\"\", \" \", \"null\", \"NULL\", \"None\", None}\n","\n","MODELS = {\n","    \"svm_offline\": {\"col\": \"pred_label\"},\n","    \"ht_online\":   {\"col\": \"actividad\"},\n","    \"arf_online\":  {\"col\": \"actividad_b\"},\n","}"],"metadata":{"id":"Nm8yUPRb4qHF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763507433054,"user_tz":300,"elapsed":1983,"user":{"displayName":"PAULA SOFIA MUNOZ ORDONEZ","userId":"07412303973976148016"}},"outputId":"a643ce8d-418d-42f9-fe7f-88f411e7391f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["CSV existe? True /content/drive/MyDrive/Colab Notebooks/TESIS/FASE ONLINE/ARCHIVOS ONLINE/windows.csv\n"]}]},{"cell_type":"markdown","source":["*Utilidades*"],"metadata":{"id":"rGXOsuEq52dh"}},{"cell_type":"code","source":["def normalize_labels(s: pd.Series) -> pd.Series:\n","    def _norm(v):\n","        if pd.isna(v): return None\n","        sv = str(v).strip()\n","        return sv if sv not in BAD_LABELS else None\n","    return s.map(_norm)\n","\n","def read_csv_robust(path: str) -> pd.DataFrame:\n","    try:\n","        return pd.read_csv(path, low_memory=False)\n","    except UnicodeDecodeError:\n","        return pd.read_csv(path, low_memory=False, encoding=\"latin-1\")\n","\n","def parse_time_cols(df: pd.DataFrame) -> pd.DataFrame:\n","    if \"received_at\" in df.columns:\n","        df[\"received_at\"] = pd.to_datetime(df[\"received_at\"], errors=\"coerce\", utc=True)\n","        df[\"t\"] = df[\"received_at\"]\n","    else:\n","        df[\"t\"] = pd.NaT\n","    if \"start_time\" in df.columns:\n","        df[\"start_time\"] = pd.to_datetime(df[\"start_time\"], errors=\"coerce\", utc=True)\n","    if \"end_time\" in df.columns:\n","        df[\"end_time\"] = pd.to_datetime(df[\"end_time\"], errors=\"coerce\", utc=True)\n","    if df[\"t\"].isna().all() and \"end_time\" in df.columns:\n","        df[\"t\"] = df[\"end_time\"]\n","    if df[\"t\"].isna().all():\n","        df = df.sort_index().copy()\n","        base = pd.Timestamp(\"2000-01-01\", tz=\"UTC\")\n","        df[\"t\"] = [base + pd.Timedelta(seconds=i) for i in range(len(df))]\n","    return df\n","def parse_args():\n","    ap = argparse.ArgumentParser()\n","    ap.add_argument(\"--input\", required=True, help=\"Ruta al CSV de windows\")\n","    ap.add_argument(\"--outdir\", default=\"resultados_windows\", help=\"Carpeta de salida\")\n","    ap.add_argument(\"--roll-sec\", type=int, default=60, help=\"Ventana (s) para rolling accuracy\")\n","    ap.add_argument(\"--min-support\", type=int, default=5, help=\"Soporte m√≠nimo por clase para PRF1\")\n","    return ap.parse_args()\n","\n","def infer_window_seconds(df: pd.DataFrame) -> float:\n","    if \"start_time\" in df.columns and \"end_time\" in df.columns:\n","        dur = (df[\"end_time\"] - df[\"start_time\"]).dt.total_seconds().dropna()\n","        if len(dur) > 0:\n","            return float(np.median(dur.values))\n","    group_cols = [c for c in [\"id_usuario\",\"session_id\"] if c in df.columns]\n","    if not group_cols:\n","        group_cols = [None]\n","    gaps = []\n","    if group_cols == [None]:\n","        t = df[\"t\"].sort_values()\n","        dt = t.diff().dt.total_seconds().dropna()\n","        gaps.extend(dt[dt > 0].tolist())\n","    else:\n","        for _, g in df.sort_values(\"t\").groupby(group_cols):\n","            t = g[\"t\"].sort_values()\n","            dt = t.diff().dt.total_seconds().dropna()\n","            gaps.extend(dt[dt > 0].tolist())\n","    if gaps:\n","        return float(np.median(gaps))\n","    return 1.0\n","\n","def ensure_group_cols(df: pd.DataFrame) -> pd.DataFrame:\n","    if \"id_usuario\" not in df.columns:\n","        df[\"id_usuario\"] = \"user_1\"\n","    if \"session_id\" not in df.columns:\n","        df[\"session_id\"] = 1\n","    return df\n","\n","def prepare(df: pd.DataFrame) -> tuple[pd.DataFrame, float]:\n","    df = df.copy()\n","    for col in [\"etiqueta\",\"pred_label\",\"actividad\",\"actividad_b\"]:\n","        if col in df.columns:\n","            df[col] = normalize_labels(df[col])\n","    df = parse_time_cols(df)\n","    df = ensure_group_cols(df)\n","    sort_cols = [c for c in [\"id_usuario\",\"session_id\",\"t\",\"id\"] if c in df.columns]\n","    df = df.sort_values(sort_cols, na_position=\"last\").reset_index(drop=True)\n","    win_s = infer_window_seconds(df)\n","    return df, win_s"],"metadata":{"id":"kGSnoZL76RNT","executionInfo":{"status":"ok","timestamp":1763507433071,"user_tz":300,"elapsed":14,"user":{"displayName":"PAULA SOFIA MUNOZ ORDONEZ","userId":"07412303973976148016"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["*Funciones para el an√°lisis*"],"metadata":{"id":"CDbVJtP26d8-"}},{"cell_type":"code","source":["def accuracy_per_group(df: pd.DataFrame, y_col: str, yhat_col: str) -> pd.DataFrame:\n","    gcols = [\"id_usuario\",\"session_id\"]\n","    mask = df[y_col].notna() & df[yhat_col].notna()\n","    d = df.loc[mask, gcols + [y_col, yhat_col]].copy()\n","    if d.empty:\n","        return pd.DataFrame(columns=gcols + [\"model\",\"accuracy\",\"n\"])\n","    d[\"correct\"] = (d[y_col] == d[yhat_col]).astype(int)\n","    res = d.groupby(gcols).agg(accuracy=(\"correct\",\"mean\"), n=(\"correct\",\"size\")).reset_index()\n","    res[\"model\"] = yhat_col\n","    return res\n","\n","def precision_recall_f1(df, y_col, yhat_col, min_support=5) -> pd.DataFrame:\n","    mask = df[y_col].notna() & df[yhat_col].notna()\n","    d = df.loc[mask, [y_col, yhat_col]].copy()\n","    if d.empty:\n","        return pd.DataFrame(columns=[\"class\",\"precision\",\"recall\",\"f1\",\"support\",\"model\"])\n","    classes = sorted(set(d[y_col].unique()).union(set(d[yhat_col].unique())))\n","    rows = []\n","    for c in classes:\n","        tp = ((d[y_col]==c) & (d[yhat_col]==c)).sum()\n","        fp = ((d[y_col]!=c) & (d[yhat_col]==c)).sum()\n","        fn = ((d[y_col]==c) & (d[yhat_col]!=c)).sum()\n","        support = (d[y_col]==c).sum()\n","        prec = tp / (tp + fp) if (tp+fp) > 0 else np.nan\n","        rec  = tp / (tp + fn) if (tp+fn) > 0 else np.nan\n","        f1   = (2*prec*rec)/(prec+rec) if (np.isfinite(prec) and np.isfinite(rec) and (prec+rec) > 0) else np.nan\n","        if support >= min_support:\n","            rows.append({\"class\": c, \"precision\":prec, \"recall\":rec, \"f1\":f1, \"support\":support})\n","    out = pd.DataFrame(rows)\n","    out[\"model\"] = yhat_col\n","    return out\n","\n","def confusion_matrix(df: pd.DataFrame, y_col: str, yhat_col: str) -> pd.DataFrame:\n","    mask = df[y_col].notna() & df[yhat_col].notna()\n","    d = df.loc[mask, [y_col, yhat_col]].copy()\n","    if d.empty:\n","        return pd.DataFrame()\n","    cm = pd.crosstab(index=d[y_col], columns=d[yhat_col], dropna=False)\n","    cm.index.name = \"true\"\n","    cm.columns.name = \"pred\"\n","    return cm\n","\n","def reaction_times(df: pd.DataFrame, y_col: str, yhat_col: str) -> pd.DataFrame:\n","    gcols = [\"id_usuario\",\"session_id\"]\n","    rows = []\n","    for (u,s), g in df.sort_values(\"t\").groupby(gcols):\n","        g = g.reset_index(drop=True)\n","        idx_nonnull = g.index[g[y_col].notna()].tolist()\n","        if len(idx_nonnull) == 0:\n","            continue\n","        last_lbl = None\n","        for idx in idx_nonnull:\n","            cur_lbl = g.at[idx, y_col]\n","            if last_lbl is None:\n","                last_lbl = cur_lbl\n","                continue\n","            if cur_lbl != last_lbl:\n","                t0 = g.at[idx, \"t\"]\n","                sub = g.loc[idx:, [yhat_col, \"t\"]]\n","                ok = sub[yhat_col] == cur_lbl\n","                if ok.any():\n","                    i_first = ok.idxmax()\n","                    lag_s = (sub.at[i_first, \"t\"] - t0).total_seconds()\n","                    rows.append({\"id_usuario\":u, \"session_id\":s, \"change_idx\":int(idx),\n","                                 \"new_label\":cur_lbl, \"t_change\":t0, \"lag_s\":lag_s, \"model\":yhat_col})\n","                else:\n","                    rows.append({\"id_usuario\":u, \"session_id\":s, \"change_idx\":int(idx),\n","                                 \"new_label\":cur_lbl, \"t_change\":t0, \"lag_s\":np.nan, \"model\":yhat_col})\n","                last_lbl = cur_lbl\n","            else:\n","                last_lbl = cur_lbl\n","    return pd.DataFrame(rows)\n","\n","def chatter_rate(df: pd.DataFrame, yhat_col: str) -> pd.DataFrame:\n","    gcols = [\"id_usuario\",\"session_id\"]\n","    rows = []\n","    for (u,s), g in df.sort_values(\"t\").groupby(gcols):\n","        gg = g.loc[g[yhat_col].notna(), [\"t\", yhat_col]].copy()\n","        if gg.empty or len(gg) < 2:\n","            continue\n","        gg = gg.sort_values(\"t\")\n","        switches = (gg[yhat_col] != gg[yhat_col].shift(1)).sum()\n","        dt = (gg[\"t\"].iloc[-1] - gg[\"t\"].iloc[0]).total_seconds() / 60.0\n","        rate = switches / dt if dt > 0 else np.nan\n","        rows.append({\"id_usuario\":u, \"session_id\":s, \"switches\":int(switches), \"minutes\":dt, \"switches_per_min\":rate, \"model\":yhat_col})\n","    return pd.DataFrame(rows)\n","\n","def learning_curve(df: pd.DataFrame, y_col: str, yhat_col: str, roll_sec: int=60) -> pd.DataFrame:\n","    gcols = [\"id_usuario\",\"session_id\"]\n","    rows = []\n","    for (u,s), g in df.sort_values(\"t\").groupby(gcols):\n","        g = g.set_index(\"t\")\n","        m = g[y_col].notna() & g[yhat_col].notna()\n","        if m.sum() == 0:\n","            continue\n","        gg = g.loc[m, [y_col, yhat_col]].copy()\n","        gg[\"ok\"] = (gg[y_col] == gg[yhat_col]).astype(int)\n","        rc = gg[\"ok\"].rolling(f\"{roll_sec}s\").mean()\n","        tmp = rc.reset_index().rename(columns={\"ok\":\"rolling_acc\"})\n","        tmp[\"id_usuario\"] = u\n","        tmp[\"session_id\"] = s\n","        tmp[\"model\"] = yhat_col\n","        rows.append(tmp)\n","    if rows:\n","        return pd.concat(rows, ignore_index=True)\n","    return pd.DataFrame(columns=[\"t\",\"rolling_acc\",\"id_usuario\",\"session_id\",\"model\"])"],"metadata":{"id":"TSy-uyk06orP","executionInfo":{"status":"ok","timestamp":1763507433119,"user_tz":300,"elapsed":28,"user":{"displayName":"PAULA SOFIA MUNOZ ORDONEZ","userId":"07412303973976148016"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["*Funciones para graficar*"],"metadata":{"id":"fN6jdgJK6veX"}},{"cell_type":"code","source":["# --------------------------- Plots ---------------------------\n","def save_confusion_plot(cm: pd.DataFrame, out_png: Path, title: str):\n","    if cm.empty: return\n","    fig, ax = plt.subplots(figsize=(6, 5))\n","    im = ax.imshow(cm.values, cmap=\"Blues\")\n","    ax.set_xticks(range(len(cm.columns)))\n","    ax.set_yticks(range(len(cm.index)))\n","    ax.set_xticklabels([str(c) for c in cm.columns], rotation=45, ha=\"right\")\n","    ax.set_yticklabels([str(i) for i in cm.index])\n","    ax.set_xlabel(\"Prediction\")\n","    ax.set_ylabel(\"true (label)\")\n","    ax.set_title(title)\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            ax.text(j, i, int(cm.values[i, j]), ha=\"center\", va=\"center\", color=\"black\")\n","    cbar = fig.colorbar(im, ax=ax)\n","    cbar.set_label(\"Number of windows\")\n","    fig.tight_layout()\n","    fig.savefig(out_png, dpi=150)\n","    plt.close(fig)\n","\n","def save_reaction_boxplot(rt: pd.DataFrame, out_png: Path, title: str):\n","    # .empty es propiedad, NO se llama como funci√≥n\n","    if rt.empty or rt[\"lag_s\"].dropna().empty:\n","        return\n","    fig, ax = plt.subplots()\n","    data = rt[\"lag_s\"].dropna().values\n","    ax.boxplot(data, vert=True)\n","    ax.set_ylabel(\"Lag (s)\")\n","    ax.set_title(title)\n","    fig.tight_layout()\n","    fig.savefig(out_png)\n","    plt.close(fig)\n","\n","\n","def etiqueta_distribution(df: pd.DataFrame) -> pd.DataFrame:\n","    d = df.loc[df[\"etiqueta\"].notna(), \"etiqueta\"].copy()\n","    if d.empty:\n","        return pd.DataFrame(columns=[\"class\",\"count\",\"pct\"])\n","    counts = d.value_counts().rename_axis(\"class\").reset_index(name=\"count\")\n","    total = counts[\"count\"].sum()\n","    counts[\"pct\"] = 100.0 * counts[\"count\"] / total\n","    return counts.sort_values(\"count\", ascending=False).reset_index(drop=True)\n","\n","def plot_etiqueta_distribution(dist_df: pd.DataFrame, out_png: Path, title: str = \"Distribuci√≥n de etiquetas (ground truth)\"):\n","    if dist_df.empty: return\n","    fig, ax = plt.subplots(figsize=(8, 4))\n","    ax.bar(dist_df[\"class\"].astype(str), dist_df[\"count\"])\n","    ax.set_xlabel(\"Etiqueta\")\n","    ax.set_ylabel(\"N√∫mero de ventanas etiquetadas\")\n","    ax.set_title(title)\n","    for i, (cnt, pct) in enumerate(zip(dist_df[\"count\"], dist_df[\"pct\"])):\n","        ax.text(i, cnt + max(1, 0.01*dist_df[\"count\"].max()), f\"{pct:.1f}%\", ha=\"center\")\n","    fig.tight_layout()\n","    fig.savefig(out_png, dpi=150)\n","    plt.close(fig)\n","\n","def aggregate_general_curve(lc_rel: pd.DataFrame, bin_minutes: float = 0.5) -> pd.DataFrame:\n","    if lc_rel.empty:\n","        return pd.DataFrame(columns=[\"rel_min_bin\",\"count\",\"mean\",\"median\",\"q25\",\"q75\"])\n","    rel_bin = (lc_rel[\"rel_min\"] / bin_minutes).floordiv(1) * bin_minutes\n","    g = lc_rel.assign(rel_min_bin=rel_bin).groupby(\"rel_min_bin\")[\"rolling_acc\"]\n","    agg = g.agg(count=\"size\", mean=\"mean\", median=\"median\",\n","                q25=lambda x: x.quantile(0.25), q75=lambda x: x.quantile(0.75)).reset_index()\n","    return agg.sort_values(\"rel_min_bin\")\n","\n","def build_learning_curve_relative(df: pd.DataFrame, y_col: str, yhat_col: str, roll_sec: int=60) -> pd.DataFrame:\n","    gcols = [\"id_usuario\",\"session_id\"]\n","    rows = []\n","    for (u,s), g in df.sort_values(\"t\").groupby(gcols):\n","        gg = g.set_index(\"t\")\n","        m = gg[y_col].notna() & gg[yhat_col].notna()\n","        if m.sum() == 0: continue\n","        gg = gg.loc[m, [y_col, yhat_col]]\n","        ok = (gg[y_col] == gg[yhat_col]).astype(int)\n","        rc = ok.rolling(f\"{roll_sec}s\").mean().dropna()\n","        if rc.empty: continue\n","        t0 = rc.index.min()\n","        rel_min = (rc.index - t0).total_seconds() / 60.0\n","        rows.append(pd.DataFrame({\"id_usuario\": u, \"session_id\": s, \"rel_min\": rel_min.values, \"rolling_acc\": rc.values}))\n","    if rows: return pd.concat(rows, ignore_index=True)\n","    return pd.DataFrame(columns=[\"id_usuario\",\"session_id\",\"rel_min\",\"rolling_acc\"])\n","\n","def plot_session_overlays(lc_rel: pd.DataFrame, out_png: Path, title: str, bin_minutes: float = 0.5, alpha_sessions: float = 0.25, lw_sessions: float = 1.0):\n","    if lc_rel.empty: return\n","    agg = aggregate_general_curve(lc_rel, bin_minutes=bin_minutes)\n","    if agg.empty: return\n","    fig, ax = plt.subplots(figsize=(8,4))\n","    for (u, s), g in lc_rel.groupby([\"id_usuario\",\"session_id\"]):\n","        g2 = g.sort_values(\"rel_min\")\n","        ax.plot(g2[\"rel_min\"], g2[\"rolling_acc\"], alpha=alpha_sessions, linewidth=lw_sessions)\n","    ax.fill_between(agg[\"rel_min_bin\"], agg[\"q25\"], agg[\"q75\"], alpha=0.15, label=\"IQR (25‚Äì75%)\")\n","    ax.plot(agg[\"rel_min_bin\"], agg[\"mean\"], linewidth=2.5, label=\"Media\")\n","    ax.set_xlabel(\"Minutos desde inicio\")\n","    ax.set_ylabel(\"Rolling acc\")\n","    ax.set_title(title)\n","    ax.set_ylim(0, 1.05)\n","    ax.grid(True, alpha=0.2)\n","    ax.legend()\n","    fig.tight_layout()\n","    fig.savefig(out_png, dpi=150)\n","    plt.close(fig)\n","\n","def plot_general_comparison(agg_ht: pd.DataFrame, agg_arf: pd.DataFrame, out_png: Path, roll_sec: int):\n","    if agg_ht.empty and agg_arf.empty: return\n","    fig, axes = plt.subplots(1, 2, figsize=(12,4), sharey=True)\n","    models = [(\"HT online\", agg_ht), (\"ARF online\", agg_arf)]\n","    for ax, (name, agg) in zip(axes, models):\n","        if agg.empty:\n","            ax.set_visible(False)\n","            continue\n","        ax.fill_between(agg[\"rel_min_bin\"], agg[\"q25\"], agg[\"q75\"], alpha=0.15, label=\"IQR (25‚Äì75%)\")\n","        ax.plot(agg[\"rel_min_bin\"], agg[\"mean\"], linewidth=2.5, label=\"Media\")\n","        ax.set_xlabel(\"Minutos desde inicio\")\n","        ax.set_title(f\"{name}\")\n","        ax.grid(True, alpha=0.2)\n","    axes[0].set_ylabel(\"Rolling acc\")\n","    axes[0].legend(loc=\"lower right\")\n","    fig.suptitle(f\"Curvas de aprendizaje generales ({roll_sec}s)\", y=1.02)\n","    fig.tight_layout()\n","    fig.savefig(out_png, dpi=150, bbox_inches=\"tight\")\n","    plt.close(fig)\n","\n","def build_per_class_pivot(prf_summary: pd.DataFrame) -> pd.DataFrame:\n","    if prf_summary.empty:\n","        return pd.DataFrame()\n","\n","    df = prf_summary.copy()\n","\n","    # pivot: m√©tricas como columnas por modelo (model_key)\n","    wide = df.pivot_table(\n","        index=\"class\",\n","        columns=\"model_key\",\n","        values=[\"precision\", \"recall\", \"f1\"],\n","        aggfunc=\"first\"\n","    )\n","\n","    # aplanar nombres de columnas: precision_ht_online, f1_arf_online, etc.\n","    wide.columns = [f\"{metric}_{model}\" for metric, model in wide.columns]\n","    wide = wide.reset_index()\n","\n","    # a√±adir support (es √∫nico por clase)\n","    supp = (df[[\"class\", \"support\"]]\n","            .dropna()\n","            .drop_duplicates(subset=[\"class\"])\n","            .set_index(\"class\"))\n","    wide = wide.set_index(\"class\").join(supp).reset_index()\n","\n","    # ordenar por support desc (opcional)\n","    if \"support\" in wide.columns:\n","        wide = wide.sort_values(\"support\", ascending=False)\n","\n","    # redondeo de m√©tricas\n","    metric_cols = [c for c in wide.columns if any(c.startswith(m) for m in [\"precision_\", \"recall_\", \"f1_\"])]\n","    wide[metric_cols] = wide[metric_cols].round(3)\n","\n","    # reordenar columnas\n","    cols_front = [\"class\"]\n","    cols_tail = [\"support\"] if \"support\" in wide.columns else []\n","    other_cols = [c for c in wide.columns if c not in cols_front + cols_tail]\n","    wide = wide[cols_front + other_cols + cols_tail]\n","\n","    return wide\n","\n","def plot_reaction_boxplot_combined(\n","    reaction_df: pd.DataFrame,\n","    out_png: Path,\n","    order=(\"svm_offline\", \"ht_online\", \"arf_online\"),\n","    title=\"Comparison of reaction lag(s)\"\n","):\n","    \"\"\"\n","    Dibuja un √∫nico boxplot con el lag de reacci√≥n de todos los modelos.\n","    - reaction_df: DF que ya generas, con columnas ['lag_s','model_key'].\n","    - order: orden de modelos a mostrar.\n","    \"\"\"\n","    if reaction_df is None or reaction_df.empty or \"lag_s\" not in reaction_df.columns:\n","        return\n","\n","    data = []\n","    labels = []\n","    for key in order:\n","        sub = reaction_df.loc[reaction_df[\"model_key\"] == key, \"lag_s\"].dropna()\n","        if sub.empty:\n","            continue\n","        data.append(sub.values)\n","        labels.append(key.replace(\"_\", \" \"))\n","\n","    if not data:\n","        return\n","\n","    fig, ax = plt.subplots(figsize=(7,5))\n","    ax.boxplot(data, labels=labels, showfliers=True)\n","    ax.set_ylabel(\"Lag (s)\")\n","    ax.set_title(title)\n","\n","    # Escala 'symlog' para ver tanto valores peque√±os como outliers grandes\n","    # (lineal cerca de 0, logar√≠tmica en valores altos)\n","    ax.set_yscale(\"symlog\", linthresh=1)\n","\n","    fig.tight_layout()\n","    fig.savefig(out_png, dpi=150)\n","    plt.close(fig)\n","\n","def plot_stability_boxplot(\n","    stability_df: pd.DataFrame,\n","    out_png: Path,\n","    order=(\"svm_offline\", \"ht_online\", \"arf_online\"),\n","    title=\"Comparativa de estabilidad (switches/min)\"\n","):\n","    \"\"\"\n","    Boxplot comparando la estabilidad (switches_per_min) entre modelos.\n","    - stability_df: DataFrame con columnas ['switches_per_min','model_key'].\n","    - order: orden en el que mostrar los modelos en el gr√°fico.\n","    \"\"\"\n","    if stability_df is None or stability_df.empty or \"switches_per_min\" not in stability_df.columns:\n","        return\n","\n","    data = []\n","    labels = []\n","    for key in order:\n","        sub = stability_df.loc[stability_df[\"model_key\"] == key, \"switches_per_min\"].dropna()\n","        if sub.empty:\n","            continue\n","        data.append(sub.values)\n","        labels.append(key.replace(\"_\", \" \"))\n","\n","    if not data:\n","        return\n","\n","    fig, ax = plt.subplots(figsize=(7,5))\n","    ax.boxplot(data, labels=labels, showfliers=True)\n","    ax.set_ylabel(\"Switches per minute\")\n","    ax.set_title(title)\n","    ax.grid(True, alpha=0.3)\n","\n","    fig.tight_layout()\n","    fig.savefig(out_png, dpi=150)\n","    plt.close(fig)"],"metadata":{"id":"6slmNLHF7F4Z","executionInfo":{"status":"ok","timestamp":1763507433169,"user_tz":300,"elapsed":48,"user":{"displayName":"PAULA SOFIA MUNOZ ORDONEZ","userId":"07412303973976148016"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["***MAIN***"],"metadata":{"id":"djfl9krb7G17"}},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3Qck9NR6Y1EE","executionInfo":{"status":"ok","timestamp":1763508709634,"user_tz":300,"elapsed":6391,"user":{"displayName":"PAULA SOFIA MUNOZ ORDONEZ","userId":"07412303973976148016"}},"outputId":"2f9c2d35-ef72-4436-c650-90f09e58e161"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Tabla sintetizada (primeras filas):\n","   class  f1_arf_online  f1_ht_online  f1_svm_offline  precision_arf_online  precision_ht_online  precision_svm_offline  recall_arf_online  recall_ht_online  recall_svm_offline  support\n","sentarse          0.795         0.954           0.120                 0.847                0.934                  0.590              0.750             0.974               0.067     4076\n"," caminar          0.390         0.737           0.643                 0.362                0.774                  0.863              0.423             0.704               0.512     2049\n","  gradas          0.078         0.297           0.122                 0.064                0.298                  0.561              0.098             0.297               0.068      542\n","  caerse          0.012         0.439           0.084                 0.021                0.433                  0.044              0.008             0.445               0.931      245\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1331158214.py:231: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n","  ax.boxplot(data, labels=labels, showfliers=True)\n","/tmp/ipython-input-1331158214.py:192: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n","  ax.boxplot(data, labels=labels, showfliers=True)\n"]}],"source":["def main():\n","    args = parse_args()\n","    outdir = Path(args.outdir)\n","    outdir.mkdir(parents=True, exist_ok=True)\n","\n","    df = read_csv_robust(args.input)\n","    df, win_s = prepare(df)\n","\n","    with open(outdir / \"README.txt\", \"w\", encoding=\"utf-8\") as f:\n","        f.write(f\"Archivo analizado: {args.input}\\n\")\n","        f.write(f\"Filas totales: {len(df)}\\n\")\n","        f.write(f\"Ventana temporal estimada: {win_s:.3f} s\\n\")\n","        f.write(f\"Usuarios √∫nicos: {df['id_usuario'].nunique()}\\n\")\n","        f.write(f\"Sesiones √∫nicas: {df['session_id'].nunique()}\\n\")\n","\n","    # --------- M√©tricas por modelo ---------\n","    acc_rows, prf_rows = [], []\n","    for model_key, cfg in MODELS.items():\n","        col = cfg[\"col\"]\n","        if col not in df.columns: continue\n","        acc = accuracy_per_group(df, \"etiqueta\", col); acc[\"model_key\"] = model_key; acc_rows.append(acc)\n","        prf = precision_recall_f1(df, \"etiqueta\", col, min_support=args.min_support); prf[\"model_key\"] = model_key; prf_rows.append(prf)\n","        cm = confusion_matrix(df, \"etiqueta\", col)\n","        save_confusion_plot(cm, outdir / f\"confusion_{model_key}.png\", f\"Confusion matrix ({model_key})\")\n","\n","    metrics_summary = pd.concat(acc_rows, ignore_index=True) if acc_rows else pd.DataFrame()\n","    prf_summary = pd.concat(prf_rows, ignore_index=True) if prf_rows else pd.DataFrame()\n","\n","    # Tabla sintetizada por clase (columnas por modelo)\n","    per_class_pivot = build_per_class_pivot(prf_summary)\n","    if not per_class_pivot.empty:\n","        per_class_pivot.to_csv(outdir / \"per_class_metrics_pivot.csv\", index=False)\n","        print(\"\\nTabla sintetizada (primeras filas):\")\n","        print(per_class_pivot.head().to_string(index=False))\n","\n","\n","    # --------- Estabilidad ---------\n","    stab_rows = []\n","    for model_key, cfg in MODELS.items():\n","        col = cfg[\"col\"]\n","        if col not in df.columns: continue\n","        stab = chatter_rate(df, col); stab[\"model_key\"] = model_key; stab_rows.append(stab)\n","    stability = pd.concat(stab_rows, ignore_index=True) if stab_rows else pd.DataFrame()\n","    stability.to_csv(outdir / \"stability_by_session.csv\", index=False)\n","\n","    # Comparativa de estabilidad en un solo gr√°fico\n","    plot_stability_boxplot(\n","        stability_df=stability,\n","        out_png=outdir / \"stability_box_all_models.png\",\n","        order=(\"svm_offline\", \"ht_online\", \"arf_online\"),\n","        title=\"Stability comparison (switches/min)\"\n","    )\n","\n","    # --------- Tiempos de reacci√≥n ---------\n","    rt_rows = []\n","    for model_key, cfg in MODELS.items():\n","        col = cfg[\"col\"]\n","        if col not in df.columns: continue\n","        rt = reaction_times(df, \"etiqueta\", col)\n","        rt[\"model_key\"] = model_key\n","        rt_rows.append(rt)\n","        # üëâ si no quieres los boxplots separados, comenta esta l√≠nea:\n","        # save_reaction_boxplot(rt, outdir / f\"reaction_box_{model_key}.png\", f\"Lag de reacci√≥n ({model_key})\")\n","\n","    reaction = pd.concat(rt_rows, ignore_index=True) if rt_rows else pd.DataFrame()\n","\n","    plot_reaction_boxplot_combined(\n","        reaction_df=reaction,\n","        out_png=outdir / \"reaction_box_all_models.png\",\n","        order=(\"svm_offline\", \"ht_online\", \"arf_online\"),\n","        title=\"Comparison of reaction lag (s)\"\n","    )\n","\n","    # --------- Curvas de aprendizaje: SOLO overlays + comparativa ---------\n","    lc_rows = []\n","    for model_key, cfg in MODELS.items():\n","        if not model_key.endswith(\"_online\"): continue\n","        col = cfg[\"col\"]\n","        if col not in df.columns: continue\n","        lc = learning_curve(df, \"etiqueta\", col, roll_sec=args.roll_sec); lc[\"model_key\"] = model_key; lc_rows.append(lc)\n","    lc_all = pd.concat(lc_rows, ignore_index=True) if lc_rows else pd.DataFrame()\n","\n","    agg_ht = pd.DataFrame(); agg_arf = pd.DataFrame()\n","\n","    if \"actividad\" in df.columns:\n","        lc_ht_rel = build_learning_curve_relative(df, \"etiqueta\", \"actividad\", roll_sec=args.roll_sec)\n","        if not lc_ht_rel.empty:\n","            plot_session_overlays(lc_ht_rel, out_png = outdir / \"learning_curve_ht_online_overlay.png\",\n","                                  title = f\"HT online: sesiones + promedio ({args.roll_sec}s)\", bin_minutes = 0.5)\n","            agg_ht = aggregate_general_curve(lc_ht_rel, bin_minutes=0.5)\n","\n","    if \"actividad_b\" in df.columns:\n","        lc_arf_rel = build_learning_curve_relative(df, \"etiqueta\", \"actividad_b\", roll_sec=args.roll_sec)\n","        if not lc_arf_rel.empty:\n","            plot_session_overlays(lc_arf_rel, out_png = outdir / \"learning_curve_arf_online_overlay.png\",\n","                                  title = f\"ARF online: sesiones + promedio ({args.roll_sec}s)\", bin_minutes = 0.5)\n","            agg_arf = aggregate_general_curve(lc_arf_rel, bin_minutes=0.5)\n","\n","    plot_general_comparison(agg_ht = agg_ht, agg_arf = agg_arf,\n","                            out_png = outdir / \"learning_curve_general_comparison.png\",\n","                            roll_sec = args.roll_sec)\n","\n","\n","    # --------- Distribuci√≥n de 'etiqueta' (ground truth) ---------\n","    dist = etiqueta_distribution(df)\n","    plot_etiqueta_distribution(dist, out_png = outdir / \"etiqueta_distribution.png\",\n","                               title   = \"Distribuci√≥n de etiquetas (ground truth)\")\n","\n","    # --------- Resumen ejecutivo ---------\n","    summary_rows = []\n","    for model_key, cfg in MODELS.items():\n","        col = cfg[\"col\"]\n","        if not metrics_summary.empty:\n","            m = metrics_summary.loc[metrics_summary[\"model_key\"]==model_key]\n","            acc_mean = (m[\"accuracy\"] * m[\"n\"]).sum() / max(1, m[\"n\"].sum()) if not m.empty else np.nan\n","        else:\n","            acc_mean = np.nan\n","        r = reaction.loc[reaction[\"model_key\"]==model_key, \"lag_s\"].dropna() if not reaction.empty else pd.Series(dtype=float)\n","        rt_med = float(r.median()) if not r.empty else np.nan\n","        st = stability.loc[stability[\"model_key\"]==model_key, \"switches_per_min\"].dropna() if not stability.empty else pd.Series(dtype=float)\n","        chat_mean = float(st.mean()) if not st.empty else np.nan\n","        summary_rows.append({\"model_key\":model_key, \"yhat_col\":col,\n","                             \"accuracy_mean\":acc_mean,\n","                             \"reaction_median_s\":rt_med,\n","                             \"switches_per_min_mean\":chat_mean,\n","                             \"win_seconds_est\":win_s})\n","    pd.DataFrame(summary_rows).to_csv(outdir / \"executive_summary.csv\", index=False)\n","\n","if __name__ == \"__main__\":\n","    import sys\n","    if 'google.colab' in sys.modules and not any(a.startswith(\"--input\") for a in sys.argv):\n","        sys.argv = [\n","            \"analisis_sl_final.py\",\n","            \"--input\", INPUT_CSV,\n","            \"--outdir\", OUT_DIR,\n","            \"--roll-sec\", \"60\",\n","            \"--min-support\", \"5\",\n","        ]\n","    main()\n"]}]}